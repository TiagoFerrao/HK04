{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKTHON 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "cpu_count = int(os.cpu_count()) if os.cpu_count() != None else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - EXTRA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1XTKTLNSCRLDS</td>\n",
       "      <td>Ellen Rappaport</td>\n",
       "      <td>Detective Inspector Erlendur Sveinsson is at h...</td>\n",
       "      <td>Mesmerizing in depth</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R  David J. Loftus   \n",
       "1  A1XTKTLNSCRLDS  Ellen Rappaport   \n",
       "2  A1A77B6DQQH436   crescamp \"esc\"   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Jenkins, a history professor and Member of Par...   \n",
       "1  Detective Inspector Erlendur Sveinsson is at h...   \n",
       "2  I didn't read this.  I purchased it for a gift...   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "1             Mesmerizing in depth  02 23, 2014            0              0   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "\n",
       "   rating  \n",
       "0       4  \n",
       "1       5  \n",
       "2       3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/book_review_labelled_data.csv')\n",
    "df_train.drop([\"overall\"], axis=1,inplace=True)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2HESNQJZ9OB7H</td>\n",
       "      <td>Jen</td>\n",
       "      <td>So boring and stupid had a hard time finishing...</td>\n",
       "      <td>Unbelievable.</td>\n",
       "      <td>02 16, 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1ABXPSFA9PC8N</td>\n",
       "      <td>Ben Parker</td>\n",
       "      <td>Ill be the first to admit i'm not the best coo...</td>\n",
       "      <td>Easy and Clear Cooking</td>\n",
       "      <td>11 7, 2012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AYVW3O6W8S5S4</td>\n",
       "      <td>Johnny in Texas</td>\n",
       "      <td>Doesn't tell you how to do anything...  just s...</td>\n",
       "      <td>not bad</td>\n",
       "      <td>02 25, 2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  \\\n",
       "0  A2HESNQJZ9OB7H              Jen   \n",
       "1  A1ABXPSFA9PC8N       Ben Parker   \n",
       "2   AYVW3O6W8S5S4  Johnny in Texas   \n",
       "\n",
       "                                          reviewText                 summary  \\\n",
       "0  So boring and stupid had a hard time finishing...           Unbelievable.   \n",
       "1  Ill be the first to admit i'm not the best coo...  Easy and Clear Cooking   \n",
       "2  Doesn't tell you how to do anything...  just s...                 not bad   \n",
       "\n",
       "    reviewTime  rating  \n",
       "0  02 16, 2014       1  \n",
       "1   11 7, 2012       5  \n",
       "2  02 25, 2014       3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/book_review_test_data_unlabelled.csv')\n",
    "df_test.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set(df, threshold=0.8):\n",
    "    df_=df.copy()\n",
    "    df_['label_aux'] = df_['helpful_count']/df_['rates_count']\n",
    "    df_['label'] = (df_['label_aux'] >= threshold)\n",
    "    df_.drop([\"label_aux\"], axis=1,inplace=True)\n",
    "    df_['label'].value_counts(normalize=True)\n",
    "    df_=df_[df_['rates_count']>0]\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49992, 8)\n",
      "(28423, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEAF4MRYHJZI</td>\n",
       "      <td>Angelia Menchan \"acvermen.blogspot.com\"</td>\n",
       "      <td>Fierce Angels by Sheri Park reads like a disse...</td>\n",
       "      <td>So FIERCE</td>\n",
       "      <td>03 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                             reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R                          David J. Loftus   \n",
       "2  A1A77B6DQQH436                           crescamp \"esc\"   \n",
       "3    AEAF4MRYHJZI  Angelia Menchan \"acvermen.blogspot.com\"   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Jenkins, a history professor and Member of Par...   \n",
       "2  I didn't read this.  I purchased it for a gift...   \n",
       "3  Fierce Angels by Sheri Park reads like a disse...   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "3                        So FIERCE  03 24, 2010            9              9   \n",
       "\n",
       "   rating  label  \n",
       "0       4   True  \n",
       "2       3  False  \n",
       "3       4   True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train=create_train_set(df_train, 0.8)\n",
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extra_features(df):\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    df_['reviewText_lower'] = df_['reviewText'].str.lower()\n",
    "    df_['reviewText_lower_no_punctuation'] = df_['reviewText_lower'].apply(lambda x: re.sub(r'[^\\w\\s]','', x))\n",
    "    df_['nb_words'] = df_['reviewText_lower_no_punctuation'].apply(lambda x: len(x.split()))\n",
    "    df_['nb_stopwords'] = df_['reviewText_lower_no_punctuation'].apply(lambda x: len([word for word in x.split() if word in stop_words]))\n",
    "    df_['avg_word_length'] = df_['reviewText_lower_no_punctuation'].apply(lambda x: np.mean([len(t) for t in x.split()]) if np.mean([len(t) for t in x.split()  if t not in stop_words]) > 0 else 0)\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    df_['reviewText_tokenized'] = df_['reviewText'].apply(lambda x: ' '.join(tokenizer.tokenize(x)))\n",
    "    df_['nb_punctuation'] = df_['reviewText_tokenized'].apply(lambda x: len([punct for punct in x.split() if punct in string.punctuation]))\n",
    "    df_['nb_punctuation_normalized'] = df_['nb_punctuation']/df_['nb_words']\n",
    "    df_['nb_stopwords_normalized'] = df_['nb_stopwords']/df_['nb_words']\n",
    "    \n",
    "    df_ = df_.drop(['reviewText_lower', 'reviewText_lower_no_punctuation', 'reviewText_tokenized'], axis=1)\n",
    "    new_cols = ['nb_words', 'nb_stopwords', 'avg_word_length', 'nb_punctuation', 'nb_punctuation_normalized', 'nb_stopwords_normalized']\n",
    "    return df_, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed, new_cols = create_extra_features(df_train)\n",
    "df_test_processed, new_cols = create_extra_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_words',\n",
       " 'nb_stopwords',\n",
       " 'avg_word_length',\n",
       " 'nb_punctuation',\n",
       " 'nb_punctuation_normalized',\n",
       " 'nb_stopwords_normalized']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"merge_entities\", after=\"ner\")\n",
    "en_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS-Tagging Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28423/28423 [16:59<00:00, 27.88it/s]\n",
      "100%|██████████| 2000/2000 [00:40<00:00, 48.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#docs_train = list(tqdm(nlp.pipe(df_train[\"reviewText\"], batch_size=20, n_process=cpu_count-1), total=len(df_train[\"reviewText\"])))\n",
    "#docs_test = list(tqdm(nlp.pipe(df_test[\"reviewText\"], batch_size=20, n_process=cpu_count-1), total=len(df_test[\"reviewText\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_adj_adv(df, docs:None):\n",
    "    \n",
    "    df_=df.copy()\n",
    "    \n",
    "    if docs is None:\n",
    "        docs_test = list(tqdm(nlp.pipe(df_[\"reviewText\"], batch_size=20, n_process=cpu_count-1), total=len(df_[\"reviewText\"])))\n",
    "\n",
    "    ## Add adjectives and adverbs count\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [[{'POS': 'ADJ'}], [{'POS': 'ADV'}]]\n",
    "    matcher.add('LOC', pattern)\n",
    "\n",
    "\n",
    "    nb_adj_adv = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        matches = matcher(doc)\n",
    "        count = 0\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]  # the matched span\n",
    "            count +=1\n",
    "        nb_adj_adv.append(count)\n",
    "    \n",
    "    df_[\"nb_adj_adv\"] = nb_adj_adv\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_processed2 = df_add_adj_adv(df=df_train_processed, docs=docs_train)\n",
    "df_test_processed2 = df_add_adj_adv(df=df_test_processed, docs=docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_words',\n",
       " 'nb_stopwords',\n",
       " 'avg_word_length',\n",
       " 'nb_punctuation',\n",
       " 'nb_punctuation_normalized',\n",
       " 'nb_stopwords_normalized',\n",
       " 'nb_adj_adv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols.append('nb_adj_adv')\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>nb_stopwords</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>nb_punctuation</th>\n",
       "      <th>nb_punctuation_normalized</th>\n",
       "      <th>nb_stopwords_normalized</th>\n",
       "      <th>nb_adj_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>93</td>\n",
       "      <td>5.656250</td>\n",
       "      <td>69</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEAF4MRYHJZI</td>\n",
       "      <td>Angelia Menchan \"acvermen.blogspot.com\"</td>\n",
       "      <td>Fierce Angels by Sheri Park reads like a disse...</td>\n",
       "      <td>So FIERCE</td>\n",
       "      <td>03 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>272</td>\n",
       "      <td>123</td>\n",
       "      <td>4.580882</td>\n",
       "      <td>37</td>\n",
       "      <td>0.136029</td>\n",
       "      <td>0.452206</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                             reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R                          David J. Loftus   \n",
       "2  A1A77B6DQQH436                           crescamp \"esc\"   \n",
       "3    AEAF4MRYHJZI  Angelia Menchan \"acvermen.blogspot.com\"   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Jenkins, a history professor and Member of Par...   \n",
       "2  I didn't read this.  I purchased it for a gift...   \n",
       "3  Fierce Angels by Sheri Park reads like a disse...   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "3                        So FIERCE  03 24, 2010            9              9   \n",
       "\n",
       "   rating  label  nb_words  nb_stopwords  avg_word_length  nb_punctuation  \\\n",
       "0       4   True       256            93         5.656250              69   \n",
       "2       3  False        25            14         3.600000               2   \n",
       "3       4   True       272           123         4.580882              37   \n",
       "\n",
       "   nb_punctuation_normalized  nb_stopwords_normalized  nb_adj_adv  \n",
       "0                   0.269531                 0.363281          49  \n",
       "2                   0.080000                 0.560000           2  \n",
       "3                   0.136029                 0.452206          41  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_processed2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>nb_adj_adv</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "      <td>258</td>\n",
       "      <td>1790</td>\n",
       "      <td>5.941860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>117</td>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEAF4MRYHJZI</td>\n",
       "      <td>Angelia Menchan \"acvermen.blogspot.com\"</td>\n",
       "      <td>Fierce Angels by Sheri Park reads like a disse...</td>\n",
       "      <td>So FIERCE</td>\n",
       "      <td>03 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>272</td>\n",
       "      <td>1557</td>\n",
       "      <td>4.724265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                             reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R                          David J. Loftus   \n",
       "2  A1A77B6DQQH436                           crescamp \"esc\"   \n",
       "3    AEAF4MRYHJZI  Angelia Menchan \"acvermen.blogspot.com\"   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Jenkins, a history professor and Member of Par...   \n",
       "2  I didn't read this.  I purchased it for a gift...   \n",
       "3  Fierce Angels by Sheri Park reads like a disse...   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "3                        So FIERCE  03 24, 2010            9              9   \n",
       "\n",
       "   rating  label  nb_adj_adv  nb_words  doc_length  avg_word_length  \n",
       "0       4   True          49       258        1790         5.941860  \n",
       "2       3  False           2        25         117         3.680000  \n",
       "3       4   True          41       272        1557         4.724265  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def df_FeatureUnion(df, columns):\n",
    "    df_=df.copy()\n",
    "    for col in columns:\n",
    "        if is_numeric_dtype(df_[col]):\n",
    "            globals()[col+'_pipe'] = Pipeline([\n",
    "                ('selector', NumberSelector(key=col)),\n",
    "                ('standard', StandardScaler())\n",
    "                ])\n",
    "        else:\n",
    "            globals()[col+'_pipe'] = Pipeline([\n",
    "                ('selector', TextSelector(key=col)),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "                ])\n",
    "    \n",
    "    feats = FeatureUnion([('reviewText', reviewText_pipe), \n",
    "                          ('nb_words', nb_words_pipe),\n",
    "                          ('nb_stopwords', nb_words_pipe),\n",
    "                          ('nb_punctuation', nb_punctuation_pipe),\n",
    "                          ('nb_punctuation_normalized', nb_punctuation_normalized_pipe),\n",
    "                          ('nb_stopwords_normalized', nb_stopwords_normalized_pipe),\n",
    "                          ('nb_adj_adv', nb_adj_adv_pipe)])    \n",
    "    \n",
    "    feature_processing = Pipeline([('feats', feats)])\n",
    "    \n",
    "    return feats    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_words',\n",
       " 'nb_stopwords',\n",
       " 'avg_word_length',\n",
       " 'nb_punctuation',\n",
       " 'nb_punctuation_normalized',\n",
       " 'nb_stopwords_normalized',\n",
       " 'nb_adj_adv']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = df_FeatureUnion(df_train_processed2, new_cols + ['reviewText','rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_pipeline(feats, X_train, X_val, y_train, y_val, X_test):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    Don't forget to add the feats to the Pipeline!\n",
    "    \"\"\"\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('clf', MultinomialNB()),\n",
    "        #('classifier', RandomForestClassifier()),\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_val_preds = pipe.predict(X_val)\n",
    "    y_test_preds = pipe.predict(X_test)\n",
    "    val_f1_score = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    return pipe, val_f1_score, y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-129d30bd52f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_processed2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpipeline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimproved_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpipeline_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-ea53eefaa214>\u001b[0m in \u001b[0;36mimproved_pipeline\u001b[0;34m(feats, X_train, X_val, y_train, y_val, X_test)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ])\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0my_val_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/slu00/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/slu00/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/slu00/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/slu00/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "Y = df_train_processed2[\"label\"]\n",
    "X = df_train_processed2.drop(columns=\"label\")\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "X_test = df_test_processed2\n",
    "pipeline_model, pipeline_score, pipeline_prediction = improved_pipeline(feats, X_train, X_val, y_train, y_val, X_test)\n",
    "\n",
    "pipeline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     28423\n",
       "unique        2\n",
       "top        True\n",
       "freq      14743\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
